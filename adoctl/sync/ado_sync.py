from __future__ import annotations

import datetime as dt
import json
import re
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import yaml

from adoctl.ado_client.http import ado_get, ado_post_json
from adoctl.ado_client.models import ADOConfig
from adoctl.util.fs import atomic_write_text, ensure_dir
from adoctl.util.yaml_emit import render_yaml_with_header
from adoctl.util.url import join_url


def _resolve_project_id(cfg: ADOConfig) -> str:
    if isinstance(cfg.project_id, str) and cfg.project_id.strip():
        return cfg.project_id.strip()
    if not cfg.project:
        raise ValueError("cfg.project is required to resolve project id.")
    project_url = join_url(cfg.org_url, "_apis", "projects", cfg.project)
    project_payload = ado_get(cfg, project_url)
    project_id = project_payload.get("id")
    if not isinstance(project_id, str) or not project_id.strip():
        raise ValueError(
            f"Unable to resolve project id for '{cfg.project}' from ADO projects endpoint."
        )
    return project_id.strip()


def _flatten_classification_paths(node: Dict[str, Any]) -> List[str]:
    paths: List[str] = []

    def normalize(path: str) -> Optional[str]:
        cleaned = path.strip().replace("/", "\\").lstrip("\\")
        parts = [part.strip() for part in cleaned.split("\\") if part.strip()]
        if not parts:
            return None
        if len(parts) >= 2 and parts[1].lower() in {"area", "areas", "iteration", "iterations"}:
            parts = [parts[0]] + parts[2:]
        if not parts:
            return None
        return "\\".join(parts)

    def walk(n: Dict[str, Any]) -> None:
        path = n.get("path")
        if isinstance(path, str) and path:
            # ADO may return paths like "\\Project\\Area\\Child" or "\\Project\\Iteration\\Sprint",
            # but ADO field values are expected as "\\Project\\Child" / "\\Project\\Sprint".
            normalized = normalize(path)
            if normalized:
                paths.append(normalized)
        for child in (n.get("children") or []):
            if isinstance(child, dict):
                walk(child)

    walk(node)
    return sorted(set(paths))


def _normalize_path_value(path: str) -> Optional[str]:
    cleaned = path.strip().replace("/", "\\").lstrip("\\")
    cleaned = re.sub(r"\\+", r"\\", cleaned)
    return cleaned if cleaned else None


def _pick_shortest_path(paths: List[str]) -> Optional[str]:
    normalized = [path for path in (_normalize_path_value(item) for item in paths) if path]
    if not normalized:
        return None
    return sorted(set(normalized), key=lambda item: (len(item.split("\\")), item.lower()))[0]


def _dedupe_preserve(items: List[str]) -> List[str]:
    seen: set = set()
    deduped: List[str] = []
    for item in items:
        normalized = _normalize_path_value(item)
        if not normalized:
            continue
        key = normalized.lower()
        if key in seen:
            continue
        seen.add(key)
        deduped.append(normalized)
    return deduped


def _load_team_defaults_policy(path: Optional[Path] = None) -> Dict[str, Dict[str, Any]]:
    config_path = path or (Path("config") / "policy" / "team_defaults.yaml")
    if not config_path.exists():
        return {}
    with config_path.open("r", encoding="utf-8") as f:
        payload = yaml.safe_load(f) or {}
    if not isinstance(payload, dict):
        return {}
    raw_overrides = payload.get("team_defaults", {})
    if not isinstance(raw_overrides, dict):
        return {}

    parsed: Dict[str, Dict[str, Any]] = {}
    for team_name, value in raw_overrides.items():
        if not isinstance(team_name, str) or not team_name.strip() or not isinstance(value, dict):
            continue
        team_key = team_name.strip().lower()
        parsed[team_key] = {
            "iteration_default": _normalize_path_value(str(value.get("iteration_default", "")).strip())
            if isinstance(value.get("iteration_default"), str)
            else None,
            "area_default": _normalize_path_value(str(value.get("area_default", "")).strip())
            if isinstance(value.get("area_default"), str)
            else None,
            "iteration_prefixes": _dedupe_preserve(
                [item for item in value.get("iteration_prefixes", []) if isinstance(item, str)]
            )
            if isinstance(value.get("iteration_prefixes"), list)
            else [],
            "area_prefixes": _dedupe_preserve([item for item in value.get("area_prefixes", []) if isinstance(item, str)])
            if isinstance(value.get("area_prefixes"), list)
            else [],
        }
    return parsed


def _dump_yaml(obj: Any, path: Path) -> None:
    ensure_dir(path.parent)
    atomic_write_text(
        path,
        render_yaml_with_header(
            obj,
            [
                "MACHINE-GENERATED FILE. DO NOT EDIT BY HAND.",
                "Generated by `adoctl sync`.",
                "User-managed policy files live under config/policy/*.yaml.",
            ],
        ),
    )


def _dump_json(obj: Any, path: Path) -> None:
    ensure_dir(path.parent)
    atomic_write_text(path, json.dumps(obj, indent=2, sort_keys=True) + "\n")


def _extract_team_iteration_paths(payload: Dict[str, Any]) -> List[str]:
    raw_items = payload.get("value", [])
    if not isinstance(raw_items, list):
        return []
    parsed: List[str] = []
    for item in raw_items:
        if not isinstance(item, dict):
            continue
        path = item.get("path")
        if isinstance(path, str) and path.strip():
            normalized = _normalize_path_value(path)
            if normalized:
                parsed.append(normalized)
    return sorted(set(parsed))


def _extract_team_area_paths(payload: Dict[str, Any]) -> List[str]:
    raw_items = payload.get("value", [])
    if not isinstance(raw_items, list):
        return []
    parsed: List[str] = []
    for item in raw_items:
        if not isinstance(item, dict):
            continue
        path = item.get("value")
        if isinstance(path, str) and path.strip():
            normalized = _normalize_path_value(path)
            if normalized:
                parsed.append(normalized)
    return sorted(set(parsed))


def _filter_team_scoped_paths(paths: List[str], prefixes: List[str]) -> List[str]:
    normalized_prefixes = [prefix.lower() for prefix in _dedupe_preserve(prefixes)]
    if not normalized_prefixes:
        return []
    scoped: List[str] = []
    for path in paths:
        normalized = _normalize_path_value(path or "")
        if not normalized:
            continue
        lowered = normalized.lower()
        for prefix in normalized_prefixes:
            if lowered == prefix or lowered.startswith(prefix + "\\"):
                scoped.append(normalized)
                break
    return sorted(set(scoped))


def _extract_default_iteration_path(payload: Dict[str, Any]) -> Optional[str]:
    raw_items = payload.get("value", [])
    if isinstance(raw_items, list):
        for item in raw_items:
            if not isinstance(item, dict):
                continue
            attributes = item.get("attributes")
            if isinstance(attributes, dict) and attributes.get("defaultTeamIteration") is True:
                path = item.get("path")
                if isinstance(path, str):
                    normalized = _normalize_path_value(path)
                    if normalized:
                        return normalized
    return None


def _extract_default_area_path(payload: Dict[str, Any]) -> Optional[str]:
    default_value = payload.get("defaultValue")
    if isinstance(default_value, str):
        normalized = _normalize_path_value(default_value)
        if normalized:
            return normalized
    return None


def _extract_identity_record(raw_member: Dict[str, Any]) -> Optional[Dict[str, Optional[str]]]:
    identity = raw_member.get("identity")
    source = identity if isinstance(identity, dict) else raw_member
    display_name = source.get("displayName")
    unique_name = source.get("uniqueName")
    mail_address = source.get("mailAddress")
    descriptor = source.get("descriptor")
    member_id = source.get("id")
    if not isinstance(display_name, str) and not isinstance(unique_name, str):
        return None
    return {
        "display_name": display_name.strip() if isinstance(display_name, str) and display_name.strip() else None,
        "unique_name": unique_name.strip() if isinstance(unique_name, str) and unique_name.strip() else None,
        "mail_address": mail_address.strip() if isinstance(mail_address, str) and mail_address.strip() else None,
        "descriptor": descriptor.strip() if isinstance(descriptor, str) and descriptor.strip() else None,
        "id": member_id.strip() if isinstance(member_id, str) and member_id.strip() else None,
    }


def _extract_team_assignable_identities(payload: Dict[str, Any]) -> List[Dict[str, Optional[str]]]:
    raw_items = payload.get("value", [])
    if not isinstance(raw_items, list):
        return []
    parsed: List[Dict[str, Optional[str]]] = []
    seen: set = set()
    for item in raw_items:
        if not isinstance(item, dict):
            continue
        record = _extract_identity_record(item)
        if record is None:
            continue
        key = (
            (record.get("display_name") or "").lower(),
            (record.get("unique_name") or "").lower(),
            (record.get("mail_address") or "").lower(),
        )
        if key in seen:
            continue
        seen.add(key)
        parsed.append(record)
    parsed.sort(key=lambda item: ((item.get("display_name") or item.get("unique_name") or "").lower()))
    return parsed


def _parse_parent_id_from_relations(relations: Any) -> Optional[int]:
    if not isinstance(relations, list):
        return None
    for relation in relations:
        if not isinstance(relation, dict):
            continue
        rel_name = relation.get("rel")
        if rel_name != "System.LinkTypes.Hierarchy-Reverse":
            continue
        url = relation.get("url")
        if not isinstance(url, str):
            continue
        match = re.search(r"/workitems/(\d+)", url.lower())
        if match:
            return int(match.group(1))
    return None


def _extract_assigned_to(value: Any) -> Optional[str]:
    if isinstance(value, str):
        cleaned = value.strip()
        return cleaned if cleaned else None
    if isinstance(value, dict):
        display = value.get("displayName")
        unique = value.get("uniqueName")
        if isinstance(display, str) and display.strip():
            return display.strip()
        if isinstance(unique, str) and unique.strip():
            return unique.strip()
    return None


def _parse_objective_and_kr_items(work_items: List[Dict[str, Any]]) -> Dict[str, Any]:
    objectives: List[Dict[str, Any]] = []
    key_results: List[Dict[str, Any]] = []
    objective_ids: set = set()

    parsed_items: List[Dict[str, Any]] = []
    for item in work_items:
        if not isinstance(item, dict):
            continue
        raw_id = item.get("id")
        if not isinstance(raw_id, int):
            continue
        fields = item.get("fields", {})
        if not isinstance(fields, dict):
            continue
        wit_name = fields.get("System.WorkItemType")
        if not isinstance(wit_name, str) or not wit_name.strip():
            continue
        parent_id: Optional[int] = None
        raw_parent = fields.get("System.Parent")
        if isinstance(raw_parent, int):
            parent_id = raw_parent
        elif isinstance(raw_parent, str) and raw_parent.isdigit():
            parent_id = int(raw_parent)
        if parent_id is None:
            parent_id = _parse_parent_id_from_relations(item.get("relations"))

        parsed_items.append(
            {
                "id": raw_id,
                "title": fields.get("System.Title"),
                "state": fields.get("System.State"),
                "work_item_type": wit_name.strip(),
                "area_path": fields.get("System.AreaPath"),
                "iteration_path": fields.get("System.IterationPath"),
                "assigned_to": _extract_assigned_to(fields.get("System.AssignedTo")),
                "parent_id": parent_id,
            }
        )

    for entry in parsed_items:
        wit_lower = str(entry["work_item_type"]).strip().lower()
        if wit_lower == "objective":
            objective_ids.add(entry["id"])
            objectives.append(entry)

    for entry in parsed_items:
        wit_lower = str(entry["work_item_type"]).strip().lower()
        if wit_lower != "key result":
            continue
        parent_id = entry.get("parent_id")
        key_result_entry = dict(entry)
        key_result_entry["parent_objective_id"] = parent_id if isinstance(parent_id, int) and parent_id in objective_ids else None
        key_results.append(key_result_entry)

    objectives.sort(key=lambda item: item["id"])
    key_results.sort(key=lambda item: item["id"])
    orphan_key_results = [item for item in key_results if item.get("parent_objective_id") is None]

    return {
        "objectives": objectives,
        "key_results": key_results,
        "orphan_key_results": orphan_key_results,
    }


def _sync_planning_semantics(
    cfg: ADOConfig,
    out_path: Path,
    teams_payload: Dict[str, Any],
    area_paths: List[str],
    iteration_paths: List[str],
    project_id: Optional[str],
) -> None:
    team_items = teams_payload.get("value", [])
    if not isinstance(team_items, list):
        team_items = []

    team_settings_raw: Dict[str, Any] = {}
    team_defaults_policy = _load_team_defaults_policy()
    project_assignable_identities: List[Dict[str, Optional[str]]] = []
    project_identity_seen: set = set()
    teams_semantics: List[Dict[str, Any]] = []
    for team_payload in team_items:
        if not isinstance(team_payload, dict):
            continue
        team_name = team_payload.get("name")
        if not isinstance(team_name, str) or not team_name.strip():
            continue
        team_name = team_name.strip()

        team_iteration_url = join_url(
            cfg.org_url, cfg.project, team_name, "_apis", "work", "teamsettings", "iterations"
        )
        team_area_url = join_url(
            cfg.org_url, cfg.project, team_name, "_apis", "work", "teamsettings", "teamfieldvalues"
        )
        team_iteration_payload = ado_get(cfg, team_iteration_url)
        team_area_payload = ado_get(cfg, team_area_url)

        team_iteration_setting_paths = _extract_team_iteration_paths(team_iteration_payload)
        team_area_setting_paths = _extract_team_area_paths(team_area_payload)

        team_policy = team_defaults_policy.get(team_name.lower(), {})
        default_prefix = _normalize_path_value(f"{cfg.project}\\{team_name}") or f"{cfg.project}\\{team_name}"
        iteration_prefixes = _dedupe_preserve([default_prefix] + list(team_policy.get("iteration_prefixes", [])))
        area_prefixes = _dedupe_preserve([default_prefix] + list(team_policy.get("area_prefixes", [])))

        scoped_iteration_paths = _filter_team_scoped_paths(iteration_paths, iteration_prefixes)
        scoped_area_paths = _filter_team_scoped_paths(area_paths, area_prefixes)

        default_iteration_candidates: List[str] = []
        if isinstance(team_policy.get("iteration_default"), str):
            default_iteration_candidates.append(team_policy["iteration_default"])
        extracted_iteration_default = _extract_default_iteration_path(team_iteration_payload)
        if extracted_iteration_default:
            default_iteration_candidates.append(extracted_iteration_default)
        shortest_iteration_settings = _pick_shortest_path(team_iteration_setting_paths)
        if shortest_iteration_settings:
            default_iteration_candidates.append(shortest_iteration_settings)
        shortest_scoped_iteration = _pick_shortest_path(scoped_iteration_paths)
        if shortest_scoped_iteration:
            default_iteration_candidates.append(shortest_scoped_iteration)
        default_iteration_candidates.append(default_prefix)

        default_area_candidates: List[str] = []
        if isinstance(team_policy.get("area_default"), str):
            default_area_candidates.append(team_policy["area_default"])
        extracted_area_default = _extract_default_area_path(team_area_payload)
        if extracted_area_default:
            default_area_candidates.append(extracted_area_default)
        shortest_area_settings = _pick_shortest_path(team_area_setting_paths)
        if shortest_area_settings:
            default_area_candidates.append(shortest_area_settings)
        shortest_scoped_area = _pick_shortest_path(scoped_area_paths)
        if shortest_scoped_area:
            default_area_candidates.append(shortest_scoped_area)
        default_area_candidates.append(default_prefix)

        default_iteration_path = _dedupe_preserve(default_iteration_candidates)[0]
        default_area_path = _dedupe_preserve(default_area_candidates)[0]

        allowed_iteration_paths = sorted(
            set(team_iteration_setting_paths) | set(scoped_iteration_paths) | {default_iteration_path}
        )
        allowed_area_paths = sorted(set(team_area_setting_paths) | set(scoped_area_paths) | {default_area_path})

        team_members_payload: Dict[str, Any] = {"value": []}
        if project_id and isinstance(team_payload.get("id"), str) and team_payload.get("id"):
            members_url = join_url(
                cfg.org_url,
                "_apis",
                "projects",
                project_id,
                "teams",
                str(team_payload.get("id")),
                "members",
            )
            try:
                team_members_payload = ado_get(cfg, members_url)
            except Exception as exc:  # noqa: BLE001 - keep sync resilient to optional identity API failures
                team_members_payload = {"value": [], "error": str(exc)}

        team_assignable_identities = _extract_team_assignable_identities(team_members_payload)
        for identity in team_assignable_identities:
            key = (
                (identity.get("display_name") or "").lower(),
                (identity.get("unique_name") or "").lower(),
                (identity.get("mail_address") or "").lower(),
            )
            if key in project_identity_seen:
                continue
            project_identity_seen.add(key)
            project_assignable_identities.append(identity)

        teams_semantics.append(
            {
                "id": team_payload.get("id"),
                "name": team_name,
                "default_iteration_path": default_iteration_path,
                "default_area_path": default_area_path,
                "allowed_iteration_paths": allowed_iteration_paths,
                "allowed_area_paths": allowed_area_paths,
                "team_settings_iteration_paths": team_iteration_setting_paths,
                "team_settings_area_paths": team_area_setting_paths,
                "assignable_identities": team_assignable_identities,
                "iteration_prefixes": iteration_prefixes,
                "area_prefixes": area_prefixes,
                "default_iteration_source": "policy"
                if isinstance(team_policy.get("iteration_default"), str)
                else (
                    "team_settings"
                    if extracted_iteration_default
                    else ("team_scoped_paths" if shortest_scoped_iteration else "fallback")
                ),
                "default_area_source": "policy"
                if isinstance(team_policy.get("area_default"), str)
                else (
                    "team_settings"
                    if extracted_area_default
                    else ("team_scoped_paths" if shortest_scoped_area else "fallback")
                ),
            }
        )

        team_settings_raw[team_name] = {
            "iterations_payload": team_iteration_payload,
            "areas_payload": team_area_payload,
            "members_payload": team_members_payload,
        }

    wiql_url = join_url(cfg.org_url, cfg.project, "_apis", "wit", "wiql")
    wiql_query = {
        "query": (
            "SELECT [System.Id] "
            "FROM WorkItems "
            "WHERE [System.TeamProject] = @project "
            "AND [System.WorkItemType] IN ('Objective', 'Key Result') "
            "ORDER BY [System.Id]"
        )
    }
    wiql_payload = ado_post_json(cfg, wiql_url, wiql_query)
    wiql_items = wiql_payload.get("workItems", [])
    objective_kr_ids: List[int] = []
    if isinstance(wiql_items, list):
        for item in wiql_items:
            if isinstance(item, dict) and isinstance(item.get("id"), int):
                objective_kr_ids.append(item["id"])

    work_items_details: List[Dict[str, Any]] = []
    if objective_kr_ids:
        requested_fields = ",".join(
            [
                "System.Id",
                "System.WorkItemType",
                "System.Title",
                "System.State",
                "System.AreaPath",
                "System.IterationPath",
                "System.AssignedTo",
                "System.Parent",
            ]
        )
        for work_item_id in objective_kr_ids:
            work_item_url = join_url(cfg.org_url, cfg.project, "_apis", "wit", "workitems", str(work_item_id))
            work_item_payload = ado_get(
                cfg,
                work_item_url,
                params={
                    "fields": requested_fields,
                },
            )
            if isinstance(work_item_payload, dict):
                work_items_details.append(work_item_payload)

    parsed_objective_kr = _parse_objective_and_kr_items(work_items_details)
    planning_context = {
        "schema_version": "1.0",
        "generated_at_utc": dt.datetime.now(dt.timezone.utc).isoformat(),
        "project": cfg.project,
        "core_team": cfg.project,
        "owner_identity_mode": "display_name",
        "project_assignable_identities": sorted(
            project_assignable_identities,
            key=lambda item: ((item.get("display_name") or item.get("unique_name") or "").lower()),
        ),
        "project_backlog_defaults": {
            "iteration_path": cfg.project,
            "area_path": cfg.project,
        },
        "teams": sorted(teams_semantics, key=lambda item: str(item["name"]).lower()),
        "objectives": parsed_objective_kr["objectives"],
        "key_results": parsed_objective_kr["key_results"],
        "orphan_key_results": parsed_objective_kr["orphan_key_results"],
    }
    _dump_yaml(planning_context, out_path / "planning_context.yaml")

    raw_dump_payload = {
        "schema_version": "1.0",
        "generated_at_utc": dt.datetime.now(dt.timezone.utc).isoformat(),
        "project": cfg.project,
        "teams_payload": teams_payload,
        "team_settings_payloads": team_settings_raw,
        "team_defaults_policy": team_defaults_policy,
        "objective_kr_wiql_payload": wiql_payload,
        "objective_kr_work_items_payload": work_items_details,
    }
    _dump_json(raw_dump_payload, out_path / "planning_sync_dump.json")


def sync_ado_to_yaml(
    cfg: ADOConfig,
    out_dir: str,
    wit_names: Optional[List[str]] = None,
    sections: Optional[Iterable[str]] = None,
) -> None:
    """
    Syncs selected ADO metadata into YAML files under out_dir.

    sections: iterable of {"projects", "paths", "teams", "wit", "planning"}
    """
    out_path = Path(out_dir)
    ensure_dir(out_path)

    requested = set(sections or ["projects", "paths", "teams", "wit", "planning"])

    teams_payload: Dict[str, Any] = {}
    normalized_teams: List[Dict[str, Any]] = []
    project_id: Optional[str] = None
    if "teams" in requested or "planning" in requested:
        if not cfg.project:
            raise ValueError("cfg.project is required to sync teams and planning metadata.")
        project_id = _resolve_project_id(cfg)
        teams_url = join_url(cfg.org_url, "_apis", "projects", project_id, "teams")
        teams_payload = ado_get(cfg, teams_url)
        raw_teams = teams_payload.get("value", [])
        if isinstance(raw_teams, list):
            normalized_teams = [
                {
                    "id": t.get("id"),
                    "name": t.get("name"),
                    "description": t.get("description"),
                    "url": t.get("url"),
                    "identity_url": t.get("identityUrl"),
                }
                for t in raw_teams
                if isinstance(t, dict)
            ]

    if "projects" in requested:
        projects_url = join_url(cfg.org_url, "_apis", "projects")
        projects = ado_get(cfg, projects_url).get("value", [])
        normalized = [
            {
                "id": p.get("id"),
                "name": p.get("name"),
                "state": p.get("state"),
                "revision": p.get("revision"),
                "visibility": p.get("visibility"),
                "url": p.get("url"),
            }
            for p in projects
        ]
        _dump_yaml({"projects": normalized}, out_path / "projects.yaml")

    area_paths: List[str] = []
    iteration_paths: List[str] = []
    if "paths" in requested or "planning" in requested:
        if not cfg.project:
            raise ValueError("cfg.project is required to sync area/iteration paths and planning metadata.")

        areas_url = join_url(cfg.org_url, cfg.project, "_apis", "wit", "classificationnodes", "areas")
        iters_url = join_url(cfg.org_url, cfg.project, "_apis", "wit", "classificationnodes", "iterations")

        areas_tree = ado_get(cfg, areas_url, params={"$depth": "100"})
        iters_tree = ado_get(cfg, iters_url, params={"$depth": "100"})

        area_paths = _flatten_classification_paths(areas_tree)
        iteration_paths = _flatten_classification_paths(iters_tree)

        if "paths" in requested:
            _dump_yaml({"area_paths": area_paths}, out_path / "paths_area.yaml")
            _dump_yaml({"iteration_paths": iteration_paths}, out_path / "paths_iteration.yaml")

    if "teams" in requested:
        _dump_yaml({"project": cfg.project, "teams": normalized_teams}, out_path / "teams.yaml")

    if "wit" in requested:
        if not cfg.project:
            raise ValueError("cfg.project is required to sync work item type fields.")

        if wit_names:
            resolved_wit_names = list(wit_names)
        else:
            wit_list_url = join_url(cfg.org_url, cfg.project, "_apis", "wit", "workitemtypes")
            wit_list = ado_get(cfg, wit_list_url).get("value", [])
            resolved_wit_names = [
                w.get("name") for w in wit_list if isinstance(w, dict) and isinstance(w.get("name"), str)
            ]
            resolved_wit_names.sort()

        wit_contract: Dict[str, Any] = {"schema_version": "1.0", "work_item_types": {}}

        for wit in resolved_wit_names:
            fields_url = join_url(
                cfg.org_url,
                cfg.project,
                "_apis",
                "wit",
                "workitemtypes",
                wit,
                "fields",
            )
            fields_json = ado_get(cfg, fields_url)
            fields = fields_json.get("value", [])

            wit_contract["work_item_types"][wit] = {
                "fields": [
                    {
                        "name": f.get("name"),
                        "reference_name": f.get("referenceName"),
                        "type": f.get("type"),
                        "read_only": f.get("readOnly", False),
                        "required": f.get("required", False),
                    }
                    for f in fields
                    if isinstance(f, dict)
                ]
            }

        _dump_yaml(wit_contract, out_path / "wit_contract.yaml")

    if "planning" in requested:
        if not cfg.project:
            raise ValueError("cfg.project is required to sync planning metadata.")
        _sync_planning_semantics(
            cfg=cfg,
            out_path=out_path,
            teams_payload=teams_payload,
            area_paths=area_paths,
            iteration_paths=iteration_paths,
            project_id=project_id,
        )

    sync_state = {
        "schema_version": "1.0",
        "synced_at_utc": dt.datetime.now(dt.timezone.utc).isoformat(),
        "org_url": cfg.org_url,
        "project": cfg.project,
        "api_version": cfg.api_version,
        "sections": sorted(requested),
        "wit_filter": list(wit_names or []),
    }
    _dump_yaml(sync_state, out_path / "_sync_state.yaml")
